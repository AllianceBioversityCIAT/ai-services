# Text Mining Microservice

This project is a microservice for intelligent document processing using LLMs (Large Language Models). It extracts structured information from documents using techniques like vector search, RAG, and prompt engineering â€” all powered by AWS Bedrock and other AI services.

---

## ğŸš€ Features

- âœ… Document ingestion from S3
- ğŸ” Semantic chunking + vector embedding with LanceDB
- ğŸ¤– Answer generation using LLM (Claude 3 Sonnet via Bedrock)
- ğŸ”’ Auth via CLARISA credentials
- ğŸ“¦ Async processing via RabbitMQ or sync via MCP
- ğŸ“¤ Slack notifications on success/failure

---

## ğŸ› ï¸ Setup Instructions

### 1. Install [uv](https://github.com/astral-sh/uv)
You can install `uv` using `curl` or `wget`:

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
# or
wget -qO- https://astral.sh/uv/install.sh | sh
```

To install a specific version (e.g., v0.6.14):

```bash
curl -LsSf https://astral.sh/uv/0.6.14/install.sh | sh
```

### 2. Initialize a virtual environment

```bash
uv venv
```

### 3. Activate the virtual environment

```bash
source .venv/bin/activate
```

### 4. Install dependencies

```bash
uv pip install -r pyproject.toml
```

---

## â–¶ï¸ Run the Microservice

You can start the microservice using:

```bash
uv run python main.py
```

This will launch the MCP server and expose the LLM-powered tools (e.g., `process_document`) via a local MCP endpoint.

---

## ğŸ§ª Example Usage via MCP Tool

You can test it with a payload like:

```json
{
  "key": "my-document.pdf",
  "bucket": "my-bucket",
  "credentials": {
    "username": "your-client-id",
    "password": "your-secret"
  }
}
```

---

## âš™ï¸ Environment Variables

Create a `.env` file in the root directory with the following:

```env
# RabbitMQ
RABBITMQ_HOST=...
RABBITMQ_PORT=5671
RABBITMQ_USERNAME=...
RABBITMQ_PASSWORD=...
RABBITMQ_QUEUE=...

# AWS
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=us-east-1

# CLARISA Auth
CLARISA_HOST=https://api.clarisa.cgiar.org
CLARISA_LOGIN=...
CLARISA_PASSWORD=...
CLARISA_MIS=MINING
CLARISA_MIS_ENV=TEST

# Slack
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

# Microservices Configuration
MS_NAME=AI Mining Microservice
```

---

## ğŸ§ª Running Tests

Run the producer test to push messages to MCP:

```bash
python app/test/test_endpoint.py
```

You can also add unit tests using `pytest`.

---

## ğŸ“‚ Project Structure

```
â””â”€â”€ ğŸ“text-mining-service
    â””â”€â”€ ğŸ“app
        â””â”€â”€ .DS_Store
        â””â”€â”€ ğŸ“db
            â””â”€â”€ ğŸ“miningdb
        â””â”€â”€ ğŸ“llm
            â””â”€â”€ mining.py
            â””â”€â”€ vectorize.py
        â””â”€â”€ ğŸ“mcp
            â””â”€â”€ client.py
            â””â”€â”€ server.py
        â””â”€â”€ ğŸ“middleware
            â””â”€â”€ auth_middleware.py
        â””â”€â”€ ğŸ“test
            â””â”€â”€ test_producer.py
        â””â”€â”€ ğŸ“utils
            â””â”€â”€ ğŸ“clarisa
                â””â”€â”€ clarisa_connection.py
                â””â”€â”€ clarisa_service.py
                â””â”€â”€ ğŸ“dto
                    â””â”€â”€ clarisa_connection_dto.py
            â””â”€â”€ ğŸ“config
                â””â”€â”€ config_util.py
            â””â”€â”€ ğŸ“logger
                â””â”€â”€ logger_util.py
            â””â”€â”€ ğŸ“notification
                â””â”€â”€ notification_service.py
            â””â”€â”€ ğŸ“prompt
                â””â”€â”€ default_prompt.py
            â””â”€â”€ ğŸ“s3
                â””â”€â”€ s3_util.py
    â””â”€â”€ ğŸ“data
        â””â”€â”€ ğŸ“logs
            â””â”€â”€ app.log
    â””â”€â”€ .DS_Store
    â””â”€â”€ .env
    â””â”€â”€ .gitignore
    â””â”€â”€ .python-version
    â””â”€â”€ main.py
    â””â”€â”€ pyproject.toml
    â””â”€â”€ README.md
    â””â”€â”€ uv.lock
```
