import os
import json
import requests
from typing import List, Dict, Optional
from requests.auth import HTTPBasicAuth
from app.utils.logger.logger_util import get_logger
from app.api.models import MappingEntry, MappingResult
from app.utils.prompts.prompt_staff import prompt_staff
from app.utils.config.config_util import STAR, CLARISA, LLM_API_URL
from app.utils.prompts.prompt_institutions import prompt_institutions

logger = get_logger()

OPENSEARCH_URL = STAR["opensearch_url"]
OPENSEARCH_USERNAME = STAR["opensearch_username"]
OPENSEARCH_PASSWORD = STAR["opensearch_password"]
OPENSEARCH_INDEX = STAR["opensearch_index"]

CL_OPENSEARCH_URL = CLARISA["opensearch_url"]
CL_OPENSEARCH_USERNAME = CLARISA["opensearch_username"]
CL_OPENSEARCH_PASSWORD = CLARISA["opensearch_password"]
CL_OPENSEARCH_INDEX = CLARISA["opensearch_index"]

INDEX_MAPPING = {
    "institution": CL_OPENSEARCH_INDEX,
    "staff": OPENSEARCH_INDEX
}


def call_llm_validation(original_value: str, candidates: List[Dict], entry_type: str) -> Optional[Dict]:
    """Call the LLM API to validate and select the best candidate"""
    try:
        candidates_text = f"Original search: '{original_value}'\n\nCANDIDATES:\n"
        
        for i, candidate in enumerate(candidates, 1):
            if entry_type == "staff":
                candidates_text += f"{i}. ID: {candidate['id']}\n"
                candidates_text += f"   Name: {candidate['name']}\n"
                candidates_text += f"   Email: {candidate.get('email', 'N/A')}\n"
                candidates_text += f"   Center: {candidate.get('center', 'N/A')}\n"
                candidates_text += f"   OpenSearch Score: {candidate['score']}\n\n"
            else:
                candidates_text += f"{i}. ID: {candidate['id']}\n"
                candidates_text += f"   Name: {candidate['name']}\n"
                candidates_text += f"   Acronym: {candidate.get('acronym', 'N/A')}\n"
                candidates_text += f"   Website: {candidate.get('website', 'N/A')}\n"
                candidates_text += f"   OpenSearch Score: {candidate['score']}\n\n"
        
        if entry_type == "staff":
            prompt = prompt_staff
        else:
            prompt = prompt_institutions

        payload = {
            "prompt": prompt,
            "input_text": candidates_text
        }
        
        logger.info(f"ü§ñ Calling LLM for validation of {len(candidates)} candidates...")
        
        response = requests.post(LLM_API_URL, json=payload, timeout=300)
        response.raise_for_status()
        
        llm_response = response.text.strip()
        
        try:
            api_result = json.loads(llm_response)
            
            if "output" in api_result and "status" in api_result:
                if api_result["status"] == "success":
                    output_text = api_result["output"]

                    result = json.loads(output_text)
                    logger.info(f"ü§ñ Parsed LLM result: {result}")
                    return result
                else:
                    logger.error(f"‚ùå LLM API returned error status: {api_result.get('status')}")
                    return None
            else:
                logger.info("ü§ñ Trying direct JSON parsing...")
                return api_result
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON decode error: {str(e)}")
            logger.info(f"ü§ñ Trying to extract JSON from markdown response...")
            
            if "```json" in llm_response:
                json_start = llm_response.find("```json") + 7
                json_end = llm_response.find("```", json_start)
                if json_end == -1:
                    json_text = llm_response[json_start:].strip()
                else:
                    json_text = llm_response[json_start:json_end].strip()
                
                logger.info(f"ü§ñ Extracted JSON text: {json_text}")

                json_text = (json_text
                           .replace('\\n', '')           # Remove escaped newlines
                           .replace('\n', '')            # Remove actual newlines
                           .replace('\\"', '"')          # Fix escaped quotes
                           .replace('\\t', '')           # Remove escaped tabs
                           .replace('\t', '')            # Remove actual tabs
                           .strip())                     # Remove leading/trailing whitespace
                
                logger.info(f"ü§ñ Cleaned JSON text: {json_text}")
                
                try:
                    result = json.loads(json_text)
                    logger.info(f"ü§ñ Successfully parsed extracted result: {result}")
                    return result
                except json.JSONDecodeError as e2:
                    logger.error(f"‚ùå Failed to parse extracted JSON: {str(e2)}")
                    logger.error(f"‚ùå Problematic JSON: {json_text}")
                    
                    try:
                        # Remove any remaining escape characters that might be problematic
                        fixed_json = json_text.replace('\\"', '"').replace('\\', '')
                        logger.info(f"ü§ñ Attempting to parse fixed JSON: {fixed_json}")
                        result = json.loads(fixed_json)
                        logger.info(f"ü§ñ Successfully parsed fixed result: {result}")
                        return result
                    except json.JSONDecodeError as e3:
                        logger.error(f"‚ùå Even fixed JSON failed: {str(e3)}")
                        logger.error(f"üîÑ LLM parsing failed completely, will use OpenSearch fallback")
                        return None
            else:
                logger.error(f"‚ùå No JSON markdown found in response")
                logger.error(f"üîÑ LLM parsing failed completely, will use OpenSearch fallback")
                return None
                
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå HTTP error calling LLM validation: {str(e)}")
        logger.error(f"üîÑ LLM call failed, will use OpenSearch fallback")
        return None
    except Exception as e:
        logger.error(f"‚ùå Error calling LLM validation: {str(e)}")
        logger.error(f"üîÑ LLM call failed, will use OpenSearch fallback")
        return None


def map_entries_to_ids(entries: List[MappingEntry]) -> List[MappingResult]:
    results = []

    for entry in entries:
        try:
            index = INDEX_MAPPING.get(entry.type)
            if not index:
                raise ValueError(f"Unsupported type '{entry.type}'")

            if entry.type == "staff":
                opensearch_url = OPENSEARCH_URL
                opensearch_username = OPENSEARCH_USERNAME
                opensearch_password = OPENSEARCH_PASSWORD
                search_fields = ["first_name^2", "last_name^2"]
            else:
                opensearch_url = CL_OPENSEARCH_URL
                opensearch_username = CL_OPENSEARCH_USERNAME
                opensearch_password = CL_OPENSEARCH_PASSWORD
                search_fields = ["acronym^2", "name"]

            url = f"{opensearch_url}/{index}/_search"
            
            query_body = {
                "size": 3,
                "query": {
                    "bool": {
                        "should": [
                            {
                                "multi_match": {
                                    "query": entry.value,
                                    "fields": search_fields,
                                    "type": "best_fields",  # Boost docs where terms appear in same field
                                    "boost": 2.0
                                }
                            },
                            {
                                "multi_match": {
                                    "query": entry.value,
                                    "fields": search_fields,
                                    "type": "cross_fields",  # Boost docs where terms appear across fields
                                    "boost": 1.0
                                }
                            }
                        ]
                    }
                }
            }

            response = requests.post(
                url,
                json=query_body,
                auth=HTTPBasicAuth(opensearch_username, opensearch_password),
                headers={"Content-Type": "application/json"}
            )
            response.raise_for_status()
            data = response.json()
            
            logger.info(f"üîç Response status: {response.status_code}")
            logger.info(f"üîç Hits found: {len(data.get('hits', {}).get('hits', []))}")

            hits = data.get("hits", {}).get("hits", [])
            if hits:
                candidates = []
                for hit in hits:
                    source = hit["_source"]
                    score = hit["_score"]

                    if entry.type == "staff":
                        candidate = {
                            "id": source.get("carnet"),
                            "name": f"{source.get('first_name', '')} {source.get('last_name', '')}".strip(),
                            "email": source.get("email"),
                            "center": source.get("center"),
                            "score": round(score, 4)
                        }
                    else:
                        candidate = {
                            "id": str(source.get("code")) if source.get("code") else None,
                            "name": source.get("name"),
                            "acronym": source.get("acronym"),
                            "website": source.get("websiteLink"),
                            "score": round(score, 4)
                        }
                    candidates.append(candidate)

                llm_result = call_llm_validation(entry.value, candidates, entry.type)
                
                logger.info(f"üìä OpenSearch returned {len(candidates)} candidates for '{entry.value}':")
                for i, candidate in enumerate(candidates, 1):
                    if entry.type == "staff":
                        logger.info(f"   {i}. ID: {candidate['id']} | Name: {candidate['name']} | Score: {candidate['score']}")
                    else:
                        logger.info(f"   {i}. ID: {candidate['id']} | Name: {candidate['name']} | Acronym: {candidate.get('acronym')} | Score: {candidate['score']}")

                if llm_result and llm_result.get("selected_candidate") is not None:
                    selected_index = llm_result["selected_candidate"] - 1
                    if 0 <= selected_index < len(candidates):
                        selected_candidate = candidates[selected_index]
                        
                        logger.info(f"ü§ñ LLM selected candidate {llm_result['selected_candidate']}: {selected_candidate['name']}")
                        logger.info(f"ü§ñ Confidence score: {llm_result.get('confidence_score', 'N/A')}/100")
                        logger.info(f"ü§ñ Reasoning: {llm_result.get('reasoning', 'No reasoning provided')}")
                        
                        results.append(MappingResult(
                            original_value=entry.value,
                            type=entry.type,
                            mapped_id=selected_candidate["id"],
                            mapped_name=selected_candidate["name"],
                            mapped_acronym=selected_candidate.get("acronym"),
                            score=llm_result.get("confidence_score")
                        ))
                    else:
                        logger.error(f"‚ùå LLM selected invalid candidate index: {selected_index}")
                        logger.info(f"üîÑ Using OpenSearch fallback - first result")
                        first_candidate = candidates[0]
                        results.append(MappingResult(
                            original_value=entry.value,
                            type=entry.type,
                            mapped_id=first_candidate["id"],
                            mapped_name=first_candidate["name"],
                            mapped_acronym=first_candidate.get("acronym"),
                            score=90
                        ))
                elif llm_result and llm_result.get("selected_candidate") is None:
                    # LLM explicitly said no reliable match
                    logger.info(f"ü§ñ LLM determined no reliable match for '{entry.value}'")
                    logger.info(f"ü§ñ Reasoning: {llm_result.get('reasoning', 'No reasoning provided')}")
                    
                    results.append(MappingResult(
                        original_value=entry.value,
                        type=entry.type,
                        mapped_id=None,
                        mapped_name=None,
                        mapped_acronym=None,
                        score=None
                    ))
                else:
                    # LLM call failed completely (parsing errors, network issues, etc.)
                    logger.info(f"üîÑ LLM validation failed, using OpenSearch fallback for '{entry.value}'")
                    logger.info(f"üîÑ Using first OpenSearch result: {candidates[0]['name']}")
                    
                    first_candidate = candidates[0]
                    results.append(MappingResult(
                        original_value=entry.value,
                        type=entry.type,
                        mapped_id=first_candidate["id"],
                        mapped_name=first_candidate["name"],
                        mapped_acronym=first_candidate.get("acronym"),
                        score=90
                    ))
            else:
                # No OpenSearch results found
                logger.info(f"üîç No OpenSearch results found for '{entry.value}'")
                results.append(MappingResult(
                    original_value=entry.value,
                    type=entry.type,
                    mapped_id=None,
                    mapped_name=None,
                    mapped_acronym=None,
                    score=None
                ))
            
            logger.info(f"‚úÖ Response generated successfully")

        except Exception as e:
            logger.error(f"‚ùå Error searching for '{entry.value}': {str(e)}")
            results.append(MappingResult(
                original_value=entry.value,
                type=entry.type,
                mapped_id=None,
                mapped_name=None,
                mapped_acronym=None,
                score=None
            ))

    return results